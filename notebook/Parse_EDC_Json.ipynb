{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "source1 =  {\"items\":[{\"id\":\"ALZ_SE_SIM_CUSTOM_TEMPLATE://eing_abs/AJ\", \"facts\": [{\"attributeId\":\"core.classType\",\"value\":\"com.infa.ldm.relational.Column\"}, {\"attributeId\":\"core.name\",\"value\":\"AJ\"}]}, {\"id\":\"ALZ_SE_SIM_CUSTOM_TEMPLATE://eing_abs/FS_SEGMENT\", \"facts\": [{\"attributeId\":\"core.classType\",\"value\":\"com.infa.ldm.relational.Column\"}, {\"attributeId\":\"core.name\",\"value\":\"FS_SEGMENT\"}]}],\"metadata\":{\"totalCount\":93}}\r\n",
        "df = sqlContext.read.json(sc.parallelize([json.dumps(source1)]),multiLine=True)\r\n",
        "df.show(truncate=False)\r\n",
        "df.printSchema()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkPool1",
              "session_id": 13,
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-05-31T19:18:10.9261458Z",
              "session_start_time": null,
              "execution_start_time": "2022-05-31T19:18:11.371697Z",
              "execution_finish_time": "2022-05-31T19:18:12.4652521Z"
            },
            "text/plain": "StatementMeta(sparkPool1, 13, 10, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n|items                                                                                                                                                                                                                                             |metadata|\n+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n|[{[{core.classType, com.infa.ldm.relational.Column}, {core.name, AJ}], ALZ_SE_SIM_CUSTOM_TEMPLATE://eing_abs/AJ}, {[{core.classType, com.infa.ldm.relational.Column}, {core.name, FS_SEGMENT}], ALZ_SE_SIM_CUSTOM_TEMPLATE://eing_abs/FS_SEGMENT}]|{93}    |\n+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n\nroot\n |-- items: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- facts: array (nullable = true)\n |    |    |    |-- element: struct (containsNull = true)\n |    |    |    |    |-- attributeId: string (nullable = true)\n |    |    |    |    |-- value: string (nullable = true)\n |    |    |-- id: string (nullable = true)\n |-- metadata: struct (nullable = true)\n |    |-- totalCount: long (nullable = true)\n\n"
          ]
        }
      ],
      "execution_count": 37,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode, arrays_zip, col, expr\r\n",
        "df1 = (df.withColumn('buffer', explode('items'))\r\n",
        "         .withColumn('facts',expr(\"buffer.facts\"))\r\n",
        "         .withColumn('id',expr(\"buffer.id\"))\r\n",
        "         .drop(*['items','metadata','buffer'])\r\n",
        ")\r\n",
        "df1.show(truncate=False)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkPool1",
              "session_id": 13,
              "statement_id": 18,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-05-31T19:31:02.9959387Z",
              "session_start_time": null,
              "execution_start_time": "2022-05-31T19:31:03.3629888Z",
              "execution_finish_time": "2022-05-31T19:31:04.3988355Z"
            },
            "text/plain": "StatementMeta(sparkPool1, 13, 18, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------+------------------------------------------------+\n|facts                                                                      |id                                              |\n+---------------------------------------------------------------------------+------------------------------------------------+\n|[{core.classType, com.infa.ldm.relational.Column}, {core.name, AJ}]        |ALZ_SE_SIM_CUSTOM_TEMPLATE://eing_abs/AJ        |\n|[{core.classType, com.infa.ldm.relational.Column}, {core.name, FS_SEGMENT}]|ALZ_SE_SIM_CUSTOM_TEMPLATE://eing_abs/FS_SEGMENT|\n+---------------------------------------------------------------------------+------------------------------------------------+\n\n"
          ]
        }
      ],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\r\n",
        "df1 = df1.withColumn(\r\n",
        "    \"header\", \r\n",
        "    F.expr(\"filter(facts, x -> x.attributeId = 'core.name')\")[0][\"value\"]\r\n",
        ")\r\n",
        "df1.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkPool1",
              "session_id": 13,
              "statement_id": 20,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-05-31T19:32:06.3217944Z",
              "session_start_time": null,
              "execution_start_time": "2022-05-31T19:32:06.8051757Z",
              "execution_finish_time": "2022-05-31T19:32:08.0884546Z"
            },
            "text/plain": "StatementMeta(sparkPool1, 13, 20, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------+\n|               facts|                  id|    header|\n+--------------------+--------------------+----------+\n|[{core.classType,...|ALZ_SE_SIM_CUSTOM...|        AJ|\n|[{core.classType,...|ALZ_SE_SIM_CUSTOM...|FS_SEGMENT|\n+--------------------+--------------------+----------+\n\n"
          ]
        }
      ],
      "execution_count": 47,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}